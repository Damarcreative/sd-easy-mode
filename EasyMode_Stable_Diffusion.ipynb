{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnTMyW41cC1E"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "aLWXPZqjsZVV"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import os\n",
        "import json\n",
        "from google.colab import output\n",
        "import warnings\n",
        "# Disable the warning message\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"IPython.core.interactiveshell\")\n",
        "\n",
        "# *--GPU Check\n",
        "\n",
        "#@markdown During the setup process, the system checks for a graphics processing unit (GPU) with enough memory to run the model. It also installs any necessary Python packages and downloads images that are used to help the model learn more effectively.\n",
        "# Run the nvidia-smi command to get the VRAM information\n",
        "result = subprocess.run([\"nvidia-smi\", \"--query-gpu=name,memory.total,memory.free\", \"--format=csv,noheader\"], capture_output=True, check=True)\n",
        "\n",
        "# Split the output by newline characters to get a list of VRAM info for each GPU\n",
        "vram_info = result.stdout.decode(\"utf-8\").strip().split(\"\\n\")\n",
        "\n",
        "# Parse the VRAM info for each GPU\n",
        "for info in vram_info:\n",
        "    name, total, free = info.split(\",\")\n",
        "    total = int(total.strip().split()[0])  # Total VRAM in MB\n",
        "    free = int(free.strip().split()[0])  # Free VRAM in MB\n",
        "    \n",
        "    print(f\"GPU: {name}, Total VRAM: {total} MB, Free VRAM: {free} MB\")\n",
        "\n",
        "if total < 15109:  # 15109MB is equivalent to 15GB\n",
        "    # Display an error message in red text\n",
        "    print(\"\\033[91mError: Not enough VRAM available. Please change the runtime to a GPU with at least 15GB VRAM.\\033[0m\")\n",
        "    raise SystemExit\n",
        "else:\n",
        "    print(\"\\033[92mYou have enough VRAM to continue\\033[0m\")\n",
        "\n",
        "# *--Installation\n",
        "\n",
        "!wget -q -O train_dreambooth.py https://github.com/geocine/sd-easy-mode/raw/main/train_dreambooth.py\n",
        "!wget -q -O convert_diffusers_to_original_stable_diffusion.py https://github.com/geocine/sd-easy-mode/raw/main/convert_diffusers_to_original_stable_diffusion.py\n",
        "!wget -q -O concepts_list.json https://github.com/geocine/sd-easy-mode/raw/main/concepts_list.json\n",
        "# URLs of the diffusers and xformers packages\n",
        "import subprocess\n",
        "from ipywidgets import IntProgress, HTML, HBox\n",
        "import time\n",
        "from datetime import timedelta\n",
        "\n",
        "class ProgressBar:\n",
        "    def __init__(self, num_items, label_text='Progress'):\n",
        "        self.num_items = num_items\n",
        "        self.start_time = time.perf_counter()\n",
        "        self.count = 0\n",
        "        self.label_text = label_text\n",
        "\n",
        "        # Create a progress bar and HTML widgets to display the labels and progress bar\n",
        "        self.f = IntProgress(min=0, max=num_items)\n",
        "        self.label1 = HTML(value=f'{label_text}: 0%')\n",
        "        self.label2 = HTML(value='', layout=dict(margin='2px 0 0 10px'))\n",
        "\n",
        "        # Group the widgets horizontally using the HBox layout\n",
        "        display(HBox([self.label1, self.f, self.label2]))\n",
        "\n",
        "    def update(self, label=''):\n",
        "        value = 1\n",
        "        self.count += value\n",
        "        self.f.value += value\n",
        "        percentage = f'{self.f.value / self.num_items * 100:.0f}'\n",
        "        self.label1.value = f'{self.label_text}: {percentage}%'\n",
        "        self.label2.value = label\n",
        "        # change bar color to green if done\n",
        "        if percentage == \"100\":\n",
        "            self.f.bar_style = 'success'\n",
        "\n",
        "    def error(self, label=''):\n",
        "        self.label2.value = 'Stopped due to error'\n",
        "        self.f.bar_style = 'danger'\n",
        "\n",
        "DIFFUSERS_URL = 'git+https://github.com/ShivamShrirao/diffusers'\n",
        "XFORMERS_URL = 'https://github.com/geocine/dreamstall-binaries/releases/download/cxx-p38-txx-linux/xformers-0.0.15.dev0+4c06c79.d20221205-cp38-cp38-linux_x86_64.whl'\n",
        "\n",
        "def install_package(package, force_reinstall=False):\n",
        "    # Check if the package is already installed using pip freeze\n",
        "    installed_packages = subprocess.run([\"pip\", \"freeze\"], capture_output=True).stdout.decode().split(\"\\n\")\n",
        "    if not force_reinstall and any(package in s for s in installed_packages):\n",
        "        return f'{package} is already installed'\n",
        "\n",
        "    if package == 'diffusers':\n",
        "        # Install the package using the URL\n",
        "        result = subprocess.run([\"pip\", \"-qq\", \"install\", DIFFUSERS_URL], capture_output=True, text=True, check=True)\n",
        "    elif package == 'xformers':\n",
        "        # Install the package using the URL\n",
        "        result = subprocess.run([\"pip\", \"install\", XFORMERS_URL], capture_output=True, text=True, check=True)\n",
        "    else:\n",
        "        # Install the package using pip\n",
        "        result = subprocess.run([\"pip\", \"install\", package], capture_output=True, text=True, check=True)\n",
        "\n",
        "    # Print the output of the command\n",
        "    # print(result.stdout)\n",
        "    return f'{package} is installed'\n",
        "# List of packages to check and install\n",
        "packages = ['diffusers', 'triton', 'accelerate==0.12.0', 'transformers', 'ftfy', 'bitsandbytes', 'xformers']\n",
        "\n",
        "# Check and install each package\n",
        "pb = ProgressBar(len(packages), \"Installing\")\n",
        "for package in packages:\n",
        "    label = install_package(package, False)\n",
        "    pb.update(label)\n",
        "print(\"\\033[92mInstallation complete\\033[0m\")\n",
        "\n",
        "# *--Settings\n",
        "\n",
        "SDD_TOKEN = \"zwx\"\n",
        "SDD_CLASS = \"person\"\n",
        "\n",
        "# check if /content/concepts_list.json exists if not remind to run install\n",
        "if not os.path.exists(\"/content/concepts_list.json\"):\n",
        "    # Display an error message in red text\n",
        "    print(\"\\033[93mPlease run the Install cell first\\033[0m\")\n",
        "    \n",
        "    # Raise a SystemExit exception to exit the cell\n",
        "    raise SystemExit\n",
        "\n",
        "# Open the JSON file and read the contents\n",
        "with open(\"/content/concepts_list.json\", \"r\") as f:\n",
        "  json_data = json.load(f)\n",
        "\n",
        "# Iterate over the object and replace the placeholders with the values\n",
        "for item in json_data:\n",
        "  for key, value in item.items():\n",
        "    item[key] = value.format(SDD_TOKEN=SDD_TOKEN, SDD_CLASS=SDD_CLASS)\n",
        "\n",
        "# Open the JSON file and write the updated contents\n",
        "with open(\"/content/concepts_list.json\", \"w\") as f:\n",
        "  json.dump(json_data, f, indent=2)\n",
        "\n",
        "MODEL_NAME = \"runwayml/stable-diffusion-v1-5\"\n",
        "\n",
        "!mkdir -p ~/.huggingface\n",
        "HUGGINGFACE_TOKEN = \"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\"\n",
        "\n",
        "# check if HUGGINGFACE_TOKEN is set\n",
        "if not HUGGINGFACE_TOKEN:\n",
        "    # Display an error message in red text\n",
        "    print(\"\\033[93mPlease set HUGGINGFACE_TOKEN first.\\033[0m\")\n",
        "    \n",
        "    # Raise a SystemExit exception to exit the cell\n",
        "    raise SystemExit\n",
        "\n",
        "!echo -n \"{HUGGINGFACE_TOKEN}\" > ~/.huggingface/token\n",
        "\n",
        "OUTPUT_DIR = f\"stable_diffusion_models/{SDD_TOKEN}\"\n",
        "OUTPUT_DIR = \"/content/\" + OUTPUT_DIR\n",
        "\n",
        "if os.path.exists(OUTPUT_DIR):\n",
        "  # Change to the directory\n",
        "  os.chdir(OUTPUT_DIR)\n",
        "  # Remove all files and directories inside the directory using the rm command\n",
        "  subprocess.run([\"rm\", \"-rf\", \"*\"], check=True)\n",
        "else:\n",
        "  # Create the directory\n",
        "  os.makedirs(OUTPUT_DIR)\n",
        "\n",
        "print(f\"[*] Models will be saved at {OUTPUT_DIR}\")\n",
        "\n",
        "unzip_directory = f\"/content/data/{SDD_CLASS}\"\n",
        "\n",
        "# Check if the unzip directory exists\n",
        "try:\n",
        "  # Get a list of the files in the unzip directory\n",
        "  files = os.listdir(unzip_directory)\n",
        "except FileNotFoundError:\n",
        "  # Create the unzip directory\n",
        "  os.makedirs(unzip_directory)\n",
        "  # Set the files list to an empty list\n",
        "  files = []\n",
        "\n",
        "#Downloading the regularization images\n",
        "zip_file = f\"{SDD_CLASS}.zip\"\n",
        "if not os.path.exists(zip_file):\n",
        "    try:\n",
        "        reg_url = f\"https://huggingface.co/datasets/geocine/sd-v1-5-regularization-images/resolve/main/{zip_file}\"\n",
        "        subprocess.run([\"wget\", \"-q\", reg_url], check=True)\n",
        "    except Exception as e:\n",
        "        # Print an error message and set the zip_file variable to None if the download fails or the user doesn't have access\n",
        "        print(f\"An error occurred while downloading the dataset: {e}\")\n",
        "        zip_file = None\n",
        "\n",
        "# Check if the unzip directory has files\n",
        "if len(files) > 0:\n",
        "  # Do not run the unzip command\n",
        "  print(\"Unzip directory has files. Skipping unzip.\")\n",
        "elif zip_file is None:\n",
        "  # Do not run the unzip command\n",
        "  print(\"Skipping unzip because the zip file was not downloaded\")\n",
        "else:\n",
        "  command = f\"unzip -l {zip_file} | wc -l\" \n",
        "  result = subprocess.run(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "  file_count = int(result.stdout.decode('utf-8').strip())\n",
        "  # Run the unzip command\n",
        "  pb = ProgressBar(file_count, \"Extracting\")\n",
        "  process = subprocess.Popen(\n",
        "    [\"unzip\", \"-j\", zip_file, \"-d\", unzip_directory], stdout=subprocess.PIPE, stderr=subprocess.PIPE\n",
        "  )\n",
        "  while process.poll() is None:\n",
        "    out = process.stdout.readline()\n",
        "    if out != '' :# and (b\"extracting\" in out):\n",
        "      current_file = out.decode(\"utf-8\").replace(\"extracting: \",\"\")\n",
        "      current_file = current_file.replace(\"inflating: \", \"\")\n",
        "      pb.update(current_file)\n",
        "  print(\"\\033[92mExtracting regularization images completed\\033[0m\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0W530tWf904D"
      },
      "source": [
        "# Upload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "32gYIDDR1aCp"
      },
      "outputs": [],
      "source": [
        "#@markdown To train the model, run this cell to upload 15-20 images of your subject. The images should be 512x512 in size and show the subject in various poses, expressions, and backgrounds. The images should show the subject in different variations. If your images are not already 512x512, you can use [this tool](https://www.birme.net/?target_width=512&target_height=512) to resize them in a batch.\n",
        "\n",
        "import os\n",
        "import json\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "# check if /content/concepts_list.json exists if not remind to run install\n",
        "if not os.path.exists(\"/content/concepts_list.json\"):\n",
        "    raise ValueError(\"Please run the Install cell first\")\n",
        "\n",
        "# Load the data from the JSON file into the concepts_list variable\n",
        "with open(\"/content/concepts_list.json\", \"r\") as f:\n",
        "    concepts_list = json.load(f)\n",
        "\n",
        "\n",
        "# Incorporate this so that users won't have to crop their images https://github.com/d8ahazard/sd_smartprocess\n",
        "for c in concepts_list:\n",
        "   prompt = c['instance_prompt']\n",
        "   prompt = prompt.format(SDD_TOKEN=SDD_TOKEN, SDD_CLASS=SDD_CLASS)\n",
        "   print(f\"Uploading instance images for `{prompt}`\")\n",
        "   uploaded = files.upload()\n",
        "   for filename in uploaded.keys():\n",
        "       dst_path = os.path.join(c['instance_data_dir'], filename)\n",
        "       # Create the instance_data_dir directory if it does not exist\n",
        "       os.makedirs(c['instance_data_dir'], exist_ok=True)\n",
        "       shutil.move(filename, dst_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qn5ILIyDJIcX"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jjcSXTp-u-Eh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "#@markdown The number of steps is currently set to auto-compute(-1), but you can adjust them to try and improve accuracy. More steps usually improve accuracy, but too many can cause the model to overfit and perform poorly on other tasks like styling. Fewer steps may result in less accurate models. Only change these settings if you understand the potential consequences and are familiar with the process. If you do adjust the number of steps, make small changes and test the model's performance.\n",
        "\n",
        "# Load the data from the JSON file into the concepts_list variable\n",
        "with open(\"/content/concepts_list.json\", \"r\") as f:\n",
        "    concepts_list = json.load(f)\n",
        "\n",
        "num_images = 0\n",
        "\n",
        "for c in concepts_list:\n",
        "    data_dir = c['instance_data_dir']\n",
        "    # replace the SDD_TOKEN placeholders with the actual values\n",
        "    data_dir = data_dir.format(SDD_TOKEN=SDD_TOKEN, SDD_CLASS=SDD_CLASS)\n",
        "    # Check if the directory exists\n",
        "    if os.path.exists(data_dir):\n",
        "        # Check if the directory is empty\n",
        "        num_files = len(os.listdir(data_dir))\n",
        "        if num_files == 0:\n",
        "            raise ValueError(f\"The directory `{data_dir}` is empty. Please upload some images using the cell above.\")\n",
        "        else:\n",
        "            num_images += num_files\n",
        "    else:\n",
        "        # Raise an exception if the directory does not exist\n",
        "        raise ValueError(f\"The directory `{data_dir}` does not exist. Please run the Upload cell first.\")\n",
        "\n",
        "def create_interpolation_function(points):\n",
        "    def interpolate(x):\n",
        "        # Find the two nearest points\n",
        "        if x < points[0][0]:\n",
        "            x1, y1 = points[0]\n",
        "            x2, y2 = points[1]\n",
        "        elif x > points[-1][0]:\n",
        "            x1, y1 = points[-2]\n",
        "            x2, y2 = points[-1]\n",
        "        else:\n",
        "            for i in range(len(points) - 1):\n",
        "                if points[i][0] <= x <= points[i+1][0]:\n",
        "                    x1, y1 = points[i]\n",
        "                    x2, y2 = points[i+1]\n",
        "                    break\n",
        "        # Interpolate the y-value and round to the nearest integer\n",
        "        y = int(y1 + (y2 - y1) * ((x - x1) / (x2 - x1)))\n",
        "        return y\n",
        "    return interpolate\n",
        "\n",
        "# interpolation computation based on Astria results\n",
        "interpolate_max_train_steps = create_interpolation_function([(10, 1611), (11, 1750), (15, 2281)])\n",
        "\n",
        "# count the number of images on the instance_data_dir\n",
        "\n",
        "# compute NUM_CLASS_IMAGES based on the number of images , num_images * 200 with a limit of 4000\n",
        "# min(num_images * 200, 4000)\n",
        "NUM_CLASS_IMAGES = num_images * 10\n",
        "SAVE_SAMPLE_PROMPT = \"photo of {TOKEN_CLASS}\"\n",
        "SAVE_SAMPLE_PROMPT = SAVE_SAMPLE_PROMPT.format(TOKEN_CLASS=f\"{SDD_TOKEN} {SDD_CLASS}\")\n",
        "MAX_TRAIN_STEPS = -1 #@param {type:\"number\"}\n",
        "if MAX_TRAIN_STEPS < 0:\n",
        "    MAX_TRAIN_STEPS = int(interpolate_max_train_steps(num_images))\n",
        "SDD_CLASS = \"person\" #@param [\"person\", \"man\", \"woman\", \"dog\", \"cat\", \"artstyle\"]\n",
        "#@markdown `SDD_CLASS` is the subject type you want to train.<br><br>\n",
        "#@markdown The default value for `SDD_CLASS` is `person`. For example, if you set `SDD_CLASS` to `dog` then use the prompt `zwx dog` on the **Generate** step.\n",
        "SAVE_INTERVAL = 10000\n",
        "SAVE_MIN_STEPS = 0\n",
        "CLEAR_MODELS = True\n",
        "SAMPLE_BATCH_SIZE = 4\n",
        "\n",
        "\n",
        "# Check SAVE_MIN_STEPS should be should be less than or equal MAX_TRAIN_STEPS\n",
        "if SAVE_MIN_STEPS > MAX_TRAIN_STEPS:\n",
        "    raise ValueError(\"Your model will not be saved if SAVE_MIN_STEPS is greater than MAX_TRAIN_STEPS.\")\n",
        "\n",
        "PREV_MODEL_STEPS = None\n",
        "g_cuda = None\n",
        "\n",
        "if CLEAR_MODELS:\n",
        "    # Run the rm command using subprocess\n",
        "    subprocess.run([\"rm\", \"-rf\", f\"/content/stable_diffusion_models/{SDD_TOKEN}/*\"])\n",
        "\n",
        "!accelerate launch train_dreambooth.py \\\n",
        "  --pretrained_model_name_or_path=$MODEL_NAME \\\n",
        "  --pretrained_vae_name_or_path=\"stabilityai/sd-vae-ft-mse\" \\\n",
        "  --output_dir=$OUTPUT_DIR \\\n",
        "  --revision=\"main\" \\\n",
        "  --with_prior_preservation --prior_loss_weight=1.0 \\\n",
        "  --seed=1337 \\\n",
        "  --resolution=512 \\\n",
        "  --train_batch_size=1 \\\n",
        "  --train_text_encoder \\\n",
        "  --mixed_precision=\"fp16\" \\\n",
        "  --use_8bit_adam \\\n",
        "  --gradient_accumulation_steps=1 \\\n",
        "  --learning_rate=1e-6 \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --num_class_images=$NUM_CLASS_IMAGES \\\n",
        "  --sample_batch_size=$SAMPLE_BATCH_SIZE \\\n",
        "  --max_train_steps=$MAX_TRAIN_STEPS \\\n",
        "  --save_interval=$SAVE_INTERVAL \\\n",
        "  --save_min_steps=$SAVE_MIN_STEPS \\\n",
        "  --save_sample_prompt=\"$SAVE_SAMPLE_PROMPT\" \\\n",
        "  --concepts_list=\"concepts_list.json\"\n",
        "# --shuffle_after_epoch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToNG4fd_dTbF"
      },
      "source": [
        "# Generate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "K6xoHWSsbcS3",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "#@markdown The default value for `SDD_CLASS` is `person`. If you trained a different class, update the prompts accordingly. For example, if you set `SDD_CLASS` to `dog` then replace `zwx {SDD_CLASS}` with `zwx dog`.<br><br>\n",
        "#@markdown To generate images, change the parameters and run the cell. Include `zwx {SDD_CLASS}` in your prompts. For example: `a photo of zwx {SDD_CLASS}`. If you want more prompt ideas, you can check out [Astria's gallery](https://www.astria.ai/gallery) and replace `sks|zwx person|man|woman` with `zwx {SDD_CLASS}`.<br><br>\n",
        "\n",
        "import torch\n",
        "from torch import autocast\n",
        "import random\n",
        "from diffusers import StableDiffusionPipeline, DDIMScheduler, EulerAncestralDiscreteScheduler\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "MODEL_STEPS = MAX_TRAIN_STEPS\n",
        "\n",
        "\n",
        "\n",
        "if \"SDD_TOKEN\" not in globals():\n",
        "    raise ValueError(\"Please run the Settings cell above.\")\n",
        "\n",
        "if \"PREV_MODEL_STEPS\" not in globals():\n",
        "    raise ValueError(\"Please run the training cell above.\")\n",
        "\n",
        "if not os.path.exists(f'/content/stable_diffusion_models/{SDD_TOKEN}/{MODEL_STEPS}'):\n",
        "    raise ValueError(f\"Model with {MODEL_STEPS} steps does not exist. Please make sure you have run the Training cell above.\")\n",
        "\n",
        "if MODEL_STEPS != PREV_MODEL_STEPS or g_cuda is None:\n",
        "  print(\"Loading model...\")\n",
        "  PREV_MODEL_STEPS = MODEL_STEPS\n",
        "  model_path = f'/content/stable_diffusion_models/{SDD_TOKEN}/{MODEL_STEPS}'             # If you want to use previously trained model saved in gdrive, replace this with the full path of model in gdrive\n",
        "  model_path = model_path.replace(\"{TOKEN}\", SDD_TOKEN)\n",
        "  scheduler = EulerAncestralDiscreteScheduler(num_train_timesteps=1000, beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\")\n",
        "  pipe = StableDiffusionPipeline.from_pretrained(model_path, scheduler=scheduler, safety_checker=None, torch_dtype=torch.float16).to(\"cuda\")\n",
        "  pipe.enable_xformers_memory_efficient_attention()\n",
        "  g_cuda = torch.Generator(device='cuda')\n",
        "\n",
        "# Make sure model_path exists\n",
        "if not os.path.exists(model_path):\n",
        "  raise ValueError(f\"Model with `{MODEL_STEPS}` steps does not exist. Please make sure you have run the training cell above and this model step exist.\")\n",
        "\n",
        "SEED = -1\n",
        "if (SEED < 0):\n",
        "  SEED = random.randint(0, 2**32 - 1) \n",
        "g_cuda.manual_seed(SEED)\n",
        "\n",
        "PROMPT = \"closeup photo of zwx person, trending on artstation, by greg rutkowski, alphonse mucha\" #@param {type:\"string\"}\n",
        "PROMPT = PROMPT.format(TOKEN_CLASS=f\"{SDD_TOKEN} {SDD_CLASS}\")\n",
        "NEGATIVE_PROMPT = \"ugly, duplicate, morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, bad anatomy, bad proportions, cloned face, disfigured, out of frame, extra limbs, bad anatomy, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, mutated hands, fused fingers, too many fingers, long neck, text, letters, signature, web address, copyright name, username, error, extra digit, fewer digits, loadscreen, grid, stock image, a stock photo, promo poster, fat\" #@param {type:\"string\"}\n",
        "NUM_IMAGES_PER_PROMPT = 4 #@param {type:\"number\"}\n",
        "GUIDANCE_SCALE = 7.5 #@param {type:\"number\"}\n",
        "INFERENCE_STEPS = 50 #@param {type:\"number\"}\n",
        "height = 512\n",
        "width = 512\n",
        "\n",
        "with autocast(\"cuda\"), torch.inference_mode():\n",
        "    images = pipe(\n",
        "        prompt=PROMPT,\n",
        "        height=height,\n",
        "        width=width,\n",
        "        negative_prompt=NEGATIVE_PROMPT,\n",
        "        num_images_per_prompt=NUM_IMAGES_PER_PROMPT,\n",
        "        num_inference_steps=INFERENCE_STEPS,\n",
        "        guidance_scale=GUIDANCE_SCALE,\n",
        "        generator=g_cuda\n",
        "    ).images\n",
        "\n",
        "text = \"\"\"\n",
        "<br>\n",
        "If you're not happy with the output, you can try adjusting the <code>GUIDANCE_SCALE</code> and <code>INFERENCE_STEPS</code> parameters to improve the accuracy and quality of the generated images. \n",
        "<br>\n",
        "If the model is not generating a likeness, try using higher quality reference photos or increasing the number of training steps, then starting the training process again.\n",
        "<br>\n",
        "<br>\n",
        "\"\"\"\n",
        "\n",
        "display(HTML(text))\n",
        "\n",
        "for img in images:\n",
        "    display(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EydphztWBiI"
      },
      "source": [
        "# Save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hHvppaFtcFA4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "if \"SDD_TOKEN\" not in globals():\n",
        "    raise ValueError(\"Please run the Settings cell above.\")\n",
        "\n",
        "#@markdown This will save your trained model to your Google Drive. You can then download it and use it offline with the desktop application [Stable Diffusion WebUI](https://github.com/AUTOMATIC1111/stable-diffusion-webui). Please join [Stable Diffusion Dreambooth Discord](https://discord.com/invite/qbMuXBXyHA), we have a helpful community.\n",
        "MODEL_STEPS = MAX_TRAIN_STEPS\n",
        "mdl_path = f\"/content/stable_diffusion_models/{SDD_TOKEN}/{MODEL_STEPS}\"\n",
        "mdl_path = mdl_path.replace(\"{TOKEN}\", SDD_TOKEN)\n",
        "ckpt_path =  mdl_path + \"/model.ckpt\"\n",
        "\n",
        "# Make sure model_path exists\n",
        "if not os.path.exists(mdl_path):\n",
        "  raise ValueError(f\"Model with `{MODEL_STEPS}` steps does not exist. Please make sure you have run the training cell above and this model step exist.\")\n",
        "\n",
        "\n",
        "!python convert_diffusers_to_original_stable_diffusion.py --model_path $mdl_path  --checkpoint_path $ckpt_path --half\n",
        "print(f\"[*] Converted ckpt saved at {ckpt_path}\")\n",
        "\n",
        "# Check if Google Drive is already mounted\n",
        "if not os.path.exists(\"/content/drive\"):\n",
        "    # Mount Google Drive\n",
        "    drive.mount(\"/content/drive\")\n",
        "\n",
        "NAME = \"me\" #@param {type:\"string\"}\n",
        "#@markdown Enter the path to save the model in Google Drive. If left empty, the model will be saved in the root of Google Drive.\n",
        "GDRIVE_PATH = \"\" #@param {type:\"string\"}\n",
        "\n",
        "# remove / from start and end of GDRIVE_PATH if they exist\n",
        "GDRIVE_PATH = GDRIVE_PATH.strip('/')\n",
        "MODEL_NAME = f\"{SDD_CLASS}-{MODEL_STEPS}-{SDD_TOKEN}-{NAME}\"\n",
        "if GDRIVE_PATH:\n",
        "    cmd = f\"cp /content/stable_diffusion_models/{SDD_TOKEN}/{MODEL_STEPS}/model.ckpt /content/drive/MyDrive/{GDRIVE_PATH}/{MODEL_NAME}.ckpt\"\n",
        "else:\n",
        "    cmd = f\"cp /content/stable_diffusion_models/{SDD_TOKEN}/{MODEL_STEPS}/model.ckpt /content/drive/MyDrive/{MODEL_NAME}.ckpt\"\n",
        "\n",
        "# Execute the command\n",
        "!{cmd}\n",
        "if GDRIVE_PATH:\n",
        "    print(f\"Model saved at /{GDRIVE_PATH}/{MODEL_NAME}.ckpt Wait for 5 minutes before closing\")\n",
        "else:\n",
        "    print(f\"Model saved at /{MODEL_NAME}.ckpt Wait for 5 minutes before closing\")\n",
        "\n",
        "print(f\"To use your model on other applications make sure to mention \\\"{SDD_TOKEN} {SDD_CLASS}\\\" in the prompt.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "607db476e417971f05b607c2dd14e77ee8262c2c4c20dea422522c60605a222a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
